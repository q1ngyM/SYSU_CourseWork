{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. 数据清洗"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "original amount 55500\n",
      "After deleting na rows 55500\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "\n",
    "# 读取\n",
    "path = \"./data/healthcare_dataset.csv\"\n",
    "\n",
    "df = pd.read_csv(path)\n",
    "\n",
    "\n",
    "# 选取要保存的列\n",
    "cols_keep = ['Name','Age','Gender','Blood Type','Medical Condition','Date of Admission', 'Doctor','Insurance Provider', 'Billing Amount','Hospital','Discharge Date','Medication','Test Results']\n",
    "df = df[cols_keep].copy()\n",
    "\n",
    "# 原始数据量\n",
    "print('original amount', len(df))\n",
    "\n",
    "# 删除缺失关键字的数据\n",
    "df = df.dropna(subset = cols_keep)\n",
    "print('After deleting na rows', len(df))\n",
    "\n",
    "df.to_csv(\"./data/cleaned_hc_dataset.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. 提取实体和关系\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "import pandas as pd\n",
    "from spacy.matcher import Matcher, PhraseMatcher\n",
    "from spacy.tokens import Span\n",
    "\n",
    "# 加载模型\n",
    "nlp = spacy.load(\"en_core_sci_sm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 自定义术语库\n",
    "TEST_TERMS = [\"Normal\", \"Abnormal\", \"Inconclusive\"]\n",
    "ADMISSION_TERMS = [\"Emergency\", \"Elective\", \"Urgent\"]\n",
    "\n",
    "# Initialize Matcher\n",
    "matcher = Matcher(nlp.vocab)\n",
    "phrase_matcher = PhraseMatcher(nlp.vocab, attr=\"LOWER\")\n",
    "\n",
    "patterns = {\n",
    "    \"TEST\": TEST_TERMS,\n",
    "    \"ADMISSION\": ADMISSION_TERMS\n",
    "}\n",
    "\n",
    "for label, terms in patterns.items():\n",
    "    phrase_matcher.add(label, [nlp.make_doc(term) for term in terms])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_entities(row):\n",
    "    entities = []\n",
    "\n",
    "    entities.append((row[\"Name\"], \"PATIENT\"))\n",
    "    entities.append((row[\"Hospital\"], \"HOSPITAL\"))\n",
    "    entities.append((row[\"Insurance Provider\"], \"INSURANCE\"))\n",
    "    entities.append((row[\"Doctor\"], \"DOCTOR\"))\n",
    "    entities.append((row[\"Blood Type\"], \"BLOOD\"))\n",
    "    entities.append((row[\"Gender\"], \"GENDER\"))\n",
    "    entities.append((row[\"Medical Condition\"], \"DISEASE\"))\n",
    "    entities.append((row[\"Billing Amount\"], \"BILL\"))\n",
    "    entities.append((row[\"Test Results\"], \"TEST\"))\n",
    "\n",
    "\n",
    "    return list(set(entities))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"./data/cleaned_hc_dataset.csv\")\n",
    "df[\"entities\"] = df.apply(extract_entities, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_relations(row):\n",
    "    relations = []\n",
    "    \n",
    "    # Patient - Hospital\n",
    "    relations.append((row[\"Name\"], \"TREATED_AT\", row[\"Hospital\"]))\n",
    "\n",
    "    # Patient - Doctor\n",
    "    relations.append((row[\"Name\"], \"TREATED_BY\", row[\"Doctor\"]))\n",
    "\n",
    "    # Patient - Insurance\n",
    "    relations.append((row[\"Name\"], \"COVERED_BY\", row[\"Insurance Provider\"]))\n",
    "\n",
    "    # Patient - Bill\n",
    "    relations.append((row[\"Name\"], \"PAY\", row[\"Billing Amount\"]))\n",
    "\n",
    "    # Patient - GENDER\n",
    "    relations.append((row[\"Name\"], \"IS\", row[\"Gender\"]))\n",
    "\n",
    "    # Patient - Result\n",
    "    relations.append((row[\"Name\"], \"DIAGNOSED_AS\", row[\"Medical Condition\"]))\n",
    "\n",
    "    # Medical Condition - Test Results\n",
    "    relations.append((row[\"Medical Condition\"], \"HAS_TEST_RESULT\", row[\"Test Results\"]))\n",
    "\n",
    "    return relations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"relations\"] = df.apply(extract_relations, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                            entities  \\\n",
      "0  [(B-, BLOOD), (Matthew Smith, DOCTOR), (Cancer...   \n",
      "1  [(Medicare, INSURANCE), (Samantha Davies, DOCT...   \n",
      "2  [(Obesity, DISEASE), (Female, GENDER), (27955....   \n",
      "3  [(Abnormal, TEST), (Medicare, INSURANCE), (Her...   \n",
      "4  [(adrIENNE bEll, PATIENT), (14238.317813937623...   \n",
      "\n",
      "                                           relations  \n",
      "0  [(Bobby JacksOn, TREATED_AT, Sons and Miller),...  \n",
      "1  [(LesLie TErRy, TREATED_AT, Kim Inc), (LesLie ...  \n",
      "2  [(DaNnY sMitH, TREATED_AT, Cook PLC), (DaNnY s...  \n",
      "3  [(andrEw waTtS, TREATED_AT, Hernandez Rogers a...  \n",
      "4  [(adrIENNE bEll, TREATED_AT, White-White), (ad...  \n"
     ]
    }
   ],
   "source": [
    "# 保存结果\n",
    "df.to_csv(\"./data/hc_dataset_with_entities_relations.csv\", index=False)\n",
    "\n",
    "# 打印部分结果进行验证\n",
    "print(df[[\"entities\", \"relations\"]].head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. 用Neo4j构建图谱并可视化关键节点"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from neo4j import GraphDatabase\n",
    "import pandas as pd\n",
    "\n",
    "# 连接到本地 Neo4j 数据库\n",
    "URI = \"bolt://localhost:7687\" \n",
    "USER = \"neo4j\"\n",
    "PASSWORD = \"password\"\n",
    "\n",
    "# 连接数据库\n",
    "driver = GraphDatabase.driver(URI, auth=(USER, PASSWORD))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 读取提取的实体和关系\n",
    "df_spacy = pd.read_csv(\"./data/hc_dataset_with_entities_relations.csv\")\n",
    "\n",
    "import ast\n",
    "df_spacy[\"entities\"] = df_spacy[\"entities\"].apply(ast.literal_eval)\n",
    "df_spacy[\"relations\"] = df_spacy[\"relations\"].apply(ast.literal_eval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 为了缩短处理时间，只展示前200行数据\n",
    "df_spacy_subset = df_spacy.head(200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 创建节点\n",
    "def create_nodes(tx, entities):\n",
    "    for entity, label in entities:\n",
    "        tx.run(f\"MERGE (n:{label} {{name: $name}})\", name=entity)\n",
    "\n",
    "# 处理数据\n",
    "with driver.session() as session:\n",
    "    for _, row in df_spacy_subset.iterrows():\n",
    "        session.write_transaction(create_nodes, row[\"entities\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def batch_create_relations(tx, relation_list):\n",
    "    query = \"\"\"\n",
    "    UNWIND $relations AS rel\n",
    "    MATCH (a {name: rel.src}), (b {name: rel.dst})\n",
    "    MERGE (a)-[:`REL_TYPE` {type: rel.rel_type}]->(b)\n",
    "    \"\"\"\n",
    "    tx.run(query, relations=relation_list)\n",
    "\n",
    "\n",
    "batch_size = 100  # 每批 500 组数据\n",
    "with driver.session() as session:\n",
    "    for i in range(0, len(df_spacy_subset), batch_size):\n",
    "        batch_relations = df_spacy_subset[\"relations\"].iloc[i : i + batch_size].explode().dropna().tolist()\n",
    "\n",
    "\n",
    "        formatted_relations = [\n",
    "            {\"src\": rel[0], \"rel_type\": rel[1], \"dst\": rel[2]} for rel in batch_relations\n",
    "        ]\n",
    "\n",
    "        session.write_transaction(batch_create_relations, formatted_relations)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "d2l",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
